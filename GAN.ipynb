{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582401d3-53b3-47ef-8741-3e8b9e96ed47",
   "metadata": {},
   "source": [
    "# GANs to Generate Realistic Faces \n",
    "* Notebook adapted from [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/)\n",
    "* Dataset: [Kaggle Faces](https://www.kaggle.com/gasgallo/faces-data-new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3477b0-f001-435b-87ed-22956f11779b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4f3af-e670-4501-a10a-2b031dba4d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fc539-3fad-4580-953c-87b4df92fe11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENERATE_RES = 3 \n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = './face_images/images/'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9114f-2063-4e1c-bbed-dbaf32b99fb3",
   "metadata": {},
   "source": [
    "# Prepare the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c928e3b-1cab-4cba-a599-9d0e691485c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_binary_path = os.path.join(DATA_PATH,\n",
    "        f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
    "\n",
    "print(f\"Looking for file: {training_binary_path}\")\n",
    "\n",
    "if not os.path.isfile(training_binary_path):\n",
    "  start = time.time()\n",
    "  print(\"Loading training images...\")\n",
    "\n",
    "  training_data = []\n",
    "  #faces_path = os.path.join(DATA_PATH,'face_images')\n",
    "  faces_path=DATA_PATH  \n",
    "  for filename in tqdm(os.listdir(faces_path)):\n",
    "      path = os.path.join(faces_path,filename)\n",
    "      image = Image.open(path).resize((GENERATE_SQUARE,\n",
    "            GENERATE_SQUARE),Image.Resampling.LANCZOS)\n",
    "      training_data.append(np.asarray(image))\n",
    "  training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,\n",
    "            GENERATE_SQUARE,IMAGE_CHANNELS))\n",
    "  training_data = training_data.astype(np.float32)\n",
    "  training_data = training_data / 127.5 - 1.\n",
    "\n",
    "\n",
    "  print(\"Saving training image binary...\")\n",
    "  np.save(training_binary_path,training_data)\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Image preprocess time: {hms_string(elapsed)}')\n",
    "else:\n",
    "  print(\"Loading previous training pickle...\")\n",
    "  training_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4561eb-3a38-4ee5-ac1f-0ce72a2c6a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data) \\\n",
    "    .shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d79318-6297-4c53-891e-f40c4553eaee",
   "metadata": {},
   "source": [
    "# Define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d26980-c7ae-47d6-adb3-e74775386560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "      model.add(BatchNormalization(momentum=0.8))\n",
    "      model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0677774-56a8-4aa4-87c9-53a274d31e48",
   "metadata": {},
   "source": [
    "# Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de2dca-663c-4015-b254-f04e5acc2682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5cc23-68c7-49e9-bdc0-9a19bc859087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), IMAGE_CHANNELS), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "            = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "\n",
    "          \n",
    "  output_path = os.path.join(DATA_PATH,'output')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "  \n",
    "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "  im = Image.fromarray(image_array)\n",
    "  im.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41aa495-3498-41ff-b44b-4bebf24e3a4e",
   "metadata": {},
   "source": [
    "# Generate Image from Untrained Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4714c4-33a9-430c-aec4-f69df74cade8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1d638-3129-46fa-a3b5-e4b928a4ec91",
   "metadata": {},
   "source": [
    "# Test the Untrained Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1c9e4-7a40-4179-a29f-70e62cf309db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e399d-d078-4ef1-8acc-9faae0bdf29c",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b7f94-f163-40ef-8e62-aa3b16e6cbff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018221e-2f84-4156-ac08-62edc4deb6c5",
   "metadata": {},
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5b4cb-1207-4945-a78c-0a28df95bb01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56c6f9-1305-4e77-93a8-9c65efad13d1",
   "metadata": {},
   "source": [
    "# Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0831a-e207-4585-a580-8c698d8db28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\\\n",
    "        gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(\\\n",
    "        disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_discriminator, \n",
    "        discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94c83-138b-4657-a68e-57032668c1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                       SEED_SIZE))\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      t = train_step(image_batch)\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           f' {hms_string(epoch_elapsed)}')\n",
    "    save_images(epoch,fixed_seed)\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d862c9-be6b-4a17-8952-b742502050db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e1ccf-1f03-4cad-811a-3832c856484f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.save('face_generator.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109eb2d-c215-44c8-80b4-855cbb37d591",
   "metadata": {},
   "source": [
    "# Load Trained Model & Generate Faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1666bec-c458-4e1b-b07a-04db9edba8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saved_generator=tf.keras.models.load_model('face_generator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed07360-e7e7-4c20-ac6e-b0a5610e5d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([3, SEED_SIZE])\n",
    "generated_image = saved_generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[1, :,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24137c1a-2053-4ac2-91f0-d9140e263179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, Image as IPImage  # Import Image from IPython.display\n",
    "\n",
    "def display_tensor_as_image(tensor, normalization_method='min-max', clip_min=0, clip_max=255, show_image=True):\n",
    "    \"\"\"\n",
    "    Displays a TensorFlow tensor as a PIL image (grayscale or RGB).\n",
    "\n",
    "    Args:\n",
    "        tensor: The input TensorFlow tensor.\n",
    "                - For grayscale: shape=(height, width), dtype=float32 or other numeric type.\n",
    "                - For RGB: shape=(height, width, 3), dtype=float32 or other numeric type.\n",
    "        normalization_method: 'min-max' (default) or 'clipping'.\n",
    "        clip_min: Minimum value for clipping (used if normalization_method='clipping').\n",
    "        clip_max: Maximum value for clipping (used if normalization_method='clipping').\n",
    "        show_image: If True, display the image. If False, just return the PIL Image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: The PIL Image object (either 'L' for grayscale or 'RGB').\n",
    "                       Returns None if there's an error.\n",
    "    \"\"\"\n",
    "    if not isinstance(tensor, tf.Tensor):\n",
    "        raise TypeError(\"Input must be a TensorFlow tensor.\")\n",
    "\n",
    "    if tensor.ndim not in (2, 3):\n",
    "        raise ValueError(\"Input tensor must be 2-dimensional (grayscale) or 3-dimensional (RGB).\")\n",
    "\n",
    "    if tensor.ndim == 3 and tensor.shape[-1] != 3:\n",
    "        raise ValueError(\"For RGB images, the last dimension of the tensor must have size 3.\")\n",
    "\n",
    "    if tensor.dtype != tf.float32:\n",
    "        print(\"Warning: Input tensor is not float32. Casting, but results may be unexpected.\")\n",
    "        tensor = tf.cast(tensor, tf.float32)\n",
    "\n",
    "    try:\n",
    "        if normalization_method == 'min-max':\n",
    "            tensor_min = tf.reduce_min(tensor)\n",
    "            tensor_max = tf.reduce_max(tensor)\n",
    "            if tensor_max - tensor_min < 1e-6:\n",
    "                normalized_tensor = tf.zeros_like(tensor)\n",
    "            else:\n",
    "                normalized_tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "\n",
    "        elif normalization_method == 'clipping':\n",
    "            clipped_tensor = tf.clip_by_value(tensor, clip_min, clip_max)\n",
    "            tensor_min = tf.reduce_min(clipped_tensor)\n",
    "            tensor_max = tf.reduce_max(clipped_tensor)\n",
    "            if tensor_max - tensor_min < 1e-6:\n",
    "                normalized_tensor = tf.zeros_like(tensor)\n",
    "            else:\n",
    "                normalized_tensor = (clipped_tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid normalization_method.  Choose 'min-max' or 'clipping'.\")\n",
    "\n",
    "        tensor_uint8 = tf.cast(normalized_tensor * 255, tf.uint8)\n",
    "        numpy_array = tensor_uint8.numpy()\n",
    "\n",
    "        if tensor.ndim == 2:\n",
    "            image = Image.fromarray(numpy_array, mode='L')\n",
    "        else:\n",
    "            image = Image.fromarray(numpy_array, mode='RGB')\n",
    "\n",
    "        if show_image:\n",
    "            display(image)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae6d14-1b43-4a6a-954d-8bceec0b0f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_tensor_as_image(generated_image[2,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dfd856-75a3-4a4d-814b-48f2b579a25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
