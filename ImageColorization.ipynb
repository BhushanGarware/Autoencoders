{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d20063-c20f-434c-ad4c-b4b176fabe72",
   "metadata": {},
   "source": [
    "# Image Colorization\n",
    "Dataset: [Realworld Occulated Faces(ROF)](https://github.com/ekremerakin/RealWorldOccludedFaces). Notebook adapted from Sreenivas Bhattiprolu, [Python for Microscopists](https://github.com/bnsreenu/python_for_microscopists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e4c7a-1aa7-4476-a30e-c78e5c3bbffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081ce6d-36e0-4e1e-ab5d-1c121be46c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b7e4b-152c-4ee3-a022-b89583014b1b",
   "metadata": {},
   "source": [
    "### Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bd201-d2f2-451e-af6d-74cc6e629c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_path = \"./Data/Color_Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184af44-f667-40b7-b25b-edf173b77983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalize images - divide by 255\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7531bb-7013-4595-81bc-f46ab8b6c00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    source_path,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    labels=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b58a99-a9c4-4b7c-bbe6-9b691d76b7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X =[]\n",
    "Y =[]\n",
    "\n",
    "for images in train:\n",
    "    for img in images:\n",
    "        try:\n",
    "          lab = rgb2lab(img)\n",
    "          X.append(lab[:,:,0]) \n",
    "          Y.append(lab[:,:,1:] / 128) #A and B values range from -127 to 128, \n",
    "          #so we divide the values by 128 to restrict values to between -1 and 1.\n",
    "        except:\n",
    "         print('error')\n",
    "        \n",
    "        \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f7928-5bb1-428e-b920-92a6099664f0",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a60e4-c7d5-421e-936f-5d290fc3e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d76dd-1495-4506-b75c-979fe4448eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Decoder\n",
    "#Decoder\n",
    "#Note: For the last layer we use tanh instead of Relu. \n",
    "#This is because we are colorizing the image in this layer using 2 filters, A and B.\n",
    "#A and B values range between -1 and 1 so tanh (or hyperbolic tangent) is used\n",
    "#as it also has the range between -1 and 1. \n",
    "#Other functions go from 0 to 1.\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c58331-57a1-4ae5-9b74-e89bad57df45",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd210a-fa07-437d-b20b-4e7a55088dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X,Y,validation_split=0.1, epochs=500, batch_size=32)\n",
    "model.save('./Models/Colorize_Autoencoder500.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76a573-b198-4b9a-a979-f21e782f91ff",
   "metadata": {},
   "source": [
    "# Evaluate Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb4b43-4ea1-47f5-b141-9ee1c65db35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img1_color=[]\n",
    "\n",
    "img1=img_to_array(load_img('./Data/Color_Images/Image1.png'))\n",
    "img1 = resize(img1 ,(256,256))\n",
    "img1_color.append(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aad6c0-6867-4a40-8e50-016e67fa9828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img1_color = np.array(img1_color, dtype=float)\n",
    "img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
    "img1_color = img1_color.reshape(img1_color.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b821665-89d7-4750-b372-17d2709c8c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output1 = model.predict(img1_color)\n",
    "output1 = output1*128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617082d-75f8-41e4-8543-5704c0202110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = np.zeros((256, 256, 3))\n",
    "result[:,:,0] = img1_color[0][:,:,0]\n",
    "result[:,:,1:] = output1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f0002-428c-47cd-839e-9fb8511bf11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_img=lab2rgb(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e2a76-721e-4c51-921f-bfc006326ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ba8fb-0440-4888-a65c-60b34c4c67bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(load_img('./Data/Color_Images/Image1.png'))\n",
    "plt.show()\n",
    "\n",
    "# Assuming out_img is your NumPy array\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecbac1-bff6-410d-8be1-6e99dbac2652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
